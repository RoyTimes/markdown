# 并行程序设计导论(1)

最近回到了天朝之后在国际化大农村长春这边明显感觉到了资源的不足，觉得我该继续读一点书，于是今天下午去了传说中的长春市图书馆去借了一点书。真是我和资本主义的图书管理差了好几个等级。图书大概就在那一个区域，但是我研究了半天也没研究明白到底是什么方式排列书的。而且书都是中文的，不是说我能读英文我装逼我自豪，是因为中文很多书翻译的简直比英语更难懂。首先读的第一本书就如题。是一本C++多线程的书。

<!-- more -->

## Parallel & Distributed & Cocurrent
好在作者有良心，这本书还是给出了英文原文的，这几个就是多线程运算的三个常用概念。Parallel就是程序独立就是在一个进程里跑独立的线程的意思最简单，也是我现在写过的一种，Distributed & Cocurrent 都是一个进程下多个线程合作完成一个事情。区别是Distributed就是所谓的分布式是不共享内存的，而Cocurrent是多个处理单元但是会共享内存。这本书主要讲解Cocurrent. 之后简单介绍了冯诺依曼结构，大概就是指令和数据分开，所以这样的话就煞笔了啊。因为数据在内存中，调取非常的耗费时间。为此系统会自动设计这个东西，现在的系统都是多任务的系统即使实在单核的电脑上，原理就是可能一个任务运行一点之后假如说需要去那一些数据的话等待数据取回的时间再去做下一个运算，让CPU一直在工作。但是还是会造成因为取回数据造成的资源浪费。解决方案其实很简单，利用Cache. 这个很好理解，但是有一些要注意的东西。

## Cache
这是一个很神奇的发明，一般来说Cache分成三级，每一层速度更快，但是更小。就像一个金字塔的形状，之后CPU提取数据的时候会从上向下提取，因为Cache能不能起到作用基本上碰运气，可能有的缓存就是没有意义的，但是有的就有意义。如果正好有意义就被成为**命中**注意，这个假如说第一层没命中的话可能第二层命中(这你不废话。)。之后就是Cache的储存机制，这个东西写在硬件上，软件无法干涉。大体分为三类，一类是Full Associative， 一类是directed mapped，一类是n-way set associated. 简单说就是第一类就相当于一坨内存中的数据糊Cache一脸，乱七八糟的放进每一行，Directed Mapped就是一一对应的，比如说内存的行数取模一个Cache之中的行数，之后就映射过去，比如说取模4的时候，第0，4，8，12行对应Cache第一行，之后很显然最后一种就是两者的折衷方案，一行内存对应n行缓存。这里一个问题就是怎么覆盖之前的数据呢。Cache才用了一个计数机制，访问的最少的区域会被优先替代以提高数据提取的命中率。

## 虚拟储存器
我不知道是翻译的问题还是什么，这本书之中出现了一个概念叫做主存。关于这个问题的讲解大概就是，主存有时候存不下大量的数据。于是有了虚拟的内存的概念。大概的原理就是，多个程序访问一块内存的时候可能真实的程序分片的时候访问同一个地址的时候会发生冲突，为了解决这个问题，于是产生了Swap Space的概念，之后数据变成了块，类似于一万个虚拟机，每个进程访问自己的内存虚拟机，这些虚拟机被称之为Page. 所以定义内存的地址的时候使用虚拟Page+Page内的Offset来实现。但是个人觉得这个设计神煞笔，但是其实没有什么办法，因为取一个内存地址都要做一万个运算，基本上是直接访问速度的一万倍以上，之后更奇葩的是这样的话必须需要一块CPU边上的缓存用于翻译，叫做Translation-Lookaside Buffer. 专门用于翻译这个奇葩的真假内存的东西。所以说从硬件原理上来说，真爱生命远离Swap Space. 那些说电脑虚拟内存越大的越好的煞笔，请你们邹凯。


## 几个基本的Parallelism
- Instruction-Level Parallelism (ILP) 是让处理器同时执行指令提高性能(废话。)一般有着流水线式操作和多发射两种操作方法，流水线就相当于一条流水线上第一个处理乘法，第二个是加法，第三个是乘方，之后可以想象后面的数据推着之前的数据这样。一次并发执行很多操作，第二种稍微复杂一点，主要是编译的时候产生，我大概需要一个具体事例说明。 
```C
//样例1
z = x + y;
if (z > 0) w = x;
else w = y

//样例2
z = x + y;
w = * ptr; 
```

对于第一个，编译器预测大多数结果是进入w = x的分支，第二个所以直接把x + y拷贝并行的拷贝过去，这样就同时地进行了两个运算。第二个假如说ptr一般不指向z，那么直接并行操作赋值和加法。假如说预测错误，那么显然需要重新执行这个过程，好的编译器预测成功率很高，优化效率也就会显著提升。
<br/>

- Thread Level Parallelism(TLP) - 这一种会让线程之间直接并列运行，相比ILP更粗略。并不是基本的指令单元的并行。属于一种Coarse-grained的并行方法。

-  Hardware Multithreading 这种之前大概说过，类似于CPU处理任务时候的分片机制，假如说一个任务需要从内存之中读取数据，那么下一个任务先执行来节约运算资源。注意，有的机器煞笔一样把每个Thread实现成了一个进程，进程切换是龟速的，大概是Threads切换的1000倍以上。

- Simultaneous Multithreading (SMT) 允许Fine-grained的线程变种，他通过允许多个线程同时使用多个功能单元来利用计算资源。注意我们可以设定优先级线程，能减少线程减速的问题。

## END
今天先讲一点最基础的，明天再继续讲解下一部分，大概是Distributed系统的CPU和内存协调的理论方法。
